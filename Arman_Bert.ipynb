{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting transformers\n",
      "  Downloading transformers-4.25.1-py3-none-any.whl (5.8 MB)\n",
      "Collecting huggingface-hub<1.0,>=0.10.0\n",
      "  Downloading huggingface_hub-0.11.1-py3-none-any.whl (182 kB)\n",
      "Collecting pyyaml>=5.1\n",
      "  Downloading PyYAML-6.0-cp310-cp310-win_amd64.whl (151 kB)\n",
      "Collecting filelock\n",
      "  Downloading filelock-3.8.2-py3-none-any.whl (10 kB)\n",
      "Collecting tqdm>=4.27\n",
      "  Downloading tqdm-4.64.1-py2.py3-none-any.whl (78 kB)\n",
      "Collecting tokenizers!=0.11.3,<0.14,>=0.11.1\n",
      "  Downloading tokenizers-0.13.2-cp310-cp310-win_amd64.whl (3.3 MB)\n",
      "Requirement already satisfied: requests in c:\\users\\arman\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from transformers) (2.28.1)\n",
      "Requirement already satisfied: numpy>=1.17 in c:\\users\\arman\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from transformers) (1.23.5)\n",
      "Requirement already satisfied: packaging>=20.0 in c:\\users\\arman\\appdata\\roaming\\python\\python310\\site-packages (from transformers) (21.3)\n",
      "Collecting regex!=2019.12.17\n",
      "  Downloading regex-2022.10.31-cp310-cp310-win_amd64.whl (267 kB)\n",
      "Requirement already satisfied: typing-extensions>=3.7.4.3 in c:\\users\\arman\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from huggingface-hub<1.0,>=0.10.0->transformers) (4.4.0)\n",
      "Requirement already satisfied: pyparsing!=3.0.5,>=2.0.2 in c:\\users\\arman\\appdata\\roaming\\python\\python310\\site-packages (from packaging>=20.0->transformers) (3.0.9)\n",
      "Requirement already satisfied: colorama in c:\\users\\arman\\appdata\\roaming\\python\\python310\\site-packages (from tqdm>=4.27->transformers) (0.4.6)\n",
      "Requirement already satisfied: charset-normalizer<3,>=2 in c:\\users\\arman\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from requests->transformers) (2.1.1)\n",
      "Requirement already satisfied: idna<4,>=2.5 in c:\\users\\arman\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from requests->transformers) (3.4)\n",
      "Requirement already satisfied: urllib3<1.27,>=1.21.1 in c:\\users\\arman\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from requests->transformers) (1.26.13)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in c:\\users\\arman\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from requests->transformers) (2022.9.24)\n",
      "Installing collected packages: tqdm, pyyaml, filelock, tokenizers, regex, huggingface-hub, transformers\n",
      "Successfully installed filelock-3.8.2 huggingface-hub-0.11.1 pyyaml-6.0 regex-2022.10.31 tokenizers-0.13.2 tqdm-4.64.1 transformers-4.25.1\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  WARNING: The script tqdm.exe is installed in 'c:\\Users\\arman\\AppData\\Local\\Programs\\Python\\Python310\\Scripts' which is not on PATH.\n",
      "  Consider adding this directory to PATH or, if you prefer to suppress this warning, use --no-warn-script-location.\n",
      "  WARNING: The script huggingface-cli.exe is installed in 'c:\\Users\\arman\\AppData\\Local\\Programs\\Python\\Python310\\Scripts' which is not on PATH.\n",
      "  Consider adding this directory to PATH or, if you prefer to suppress this warning, use --no-warn-script-location.\n",
      "  WARNING: The script transformers-cli.exe is installed in 'c:\\Users\\arman\\AppData\\Local\\Programs\\Python\\Python310\\Scripts' which is not on PATH.\n",
      "  Consider adding this directory to PATH or, if you prefer to suppress this warning, use --no-warn-script-location.\n",
      "WARNING: You are using pip version 21.2.3; however, version 22.3.1 is available.\n",
      "You should consider upgrading via the 'c:\\Users\\arman\\AppData\\Local\\Programs\\Python\\Python310\\python.exe -m pip install --upgrade pip' command.\n"
     ]
    }
   ],
   "source": [
    "pip install transformers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torchvision\n",
    "import torchvision.transforms as transforms\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "train = pd.read_json(\"data/train.jsonl\",lines=True)\n",
    "test = pd.read_json(\"data/test.jsonl\",lines=True)\n",
    "dev = pd.read_json(\"data/dev.jsonl\",lines=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\arman\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\tqdm\\auto.py:22: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n",
      "Downloading: 100%|██████████| 631/631 [00:00<00:00, 210kB/s]\n",
      "c:\\Users\\arman\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\huggingface_hub\\file_download.py:127: UserWarning: `huggingface_hub` cache-system uses symlinks by default to efficiently store duplicated files but your machine does not support them in C:\\Users\\arman\\.cache\\huggingface\\hub. Caching files will still work but in a degraded version that might require more space on your disk. This warning can be disabled by setting the `HF_HUB_DISABLE_SYMLINKS_WARNING` environment variable. For more details, see https://huggingface.co/docs/huggingface_hub/how-to-cache#limitations.\n",
      "To support symlinks on Windows, you either need to activate Developer Mode or to run Python as an administrator. In order to see activate developer mode, see this article: https://docs.microsoft.com/en-us/windows/apps/get-started/enable-your-device-for-development\n",
      "  warnings.warn(message)\n",
      "Downloading: 100%|██████████| 448M/448M [02:17<00:00, 3.26MB/s] \n",
      "Some weights of the model checkpoint at uclanlp/visualbert-vqa-coco-pre were not used when initializing VisualBertModel: ['cls.predictions.bias', 'cls.predictions.transform.LayerNorm.weight', 'cls.predictions.transform.dense.weight', 'cls.seq_relationship.bias', 'cls.predictions.transform.LayerNorm.bias', 'cls.predictions.decoder.weight', 'cls.seq_relationship.weight', 'cls.predictions.decoder.bias', 'cls.predictions.transform.dense.bias']\n",
      "- This IS expected if you are initializing VisualBertModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing VisualBertModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
      "Downloading: 100%|██████████| 232k/232k [00:00<00:00, 658kB/s] \n",
      "Downloading: 100%|██████████| 28.0/28.0 [00:00<00:00, 14.2kB/s]\n",
      "Downloading: 100%|██████████| 570/570 [00:00<00:00, 285kB/s]\n"
     ]
    },
    {
     "ename": "NameError",
     "evalue": "name 'get_visual_embeddings' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[13], line 9\u001b[0m\n\u001b[0;32m      7\u001b[0m inputs \u001b[39m=\u001b[39m tokenizer(\u001b[39m\"\u001b[39m\u001b[39mWhat is the man eating?\u001b[39m\u001b[39m\"\u001b[39m, return_tensors\u001b[39m=\u001b[39m\u001b[39m\"\u001b[39m\u001b[39mpt\u001b[39m\u001b[39m\"\u001b[39m)\n\u001b[0;32m      8\u001b[0m \u001b[39m# this is a custom function that returns the visual embeddings given the image path\u001b[39;00m\n\u001b[1;32m----> 9\u001b[0m visual_embeds \u001b[39m=\u001b[39m get_visual_embeddings(image_path)\n\u001b[0;32m     11\u001b[0m visual_token_type_ids \u001b[39m=\u001b[39m torch\u001b[39m.\u001b[39mones(visual_embeds\u001b[39m.\u001b[39mshape[:\u001b[39m-\u001b[39m\u001b[39m1\u001b[39m], dtype\u001b[39m=\u001b[39mtorch\u001b[39m.\u001b[39mlong)\n\u001b[0;32m     12\u001b[0m visual_attention_mask \u001b[39m=\u001b[39m torch\u001b[39m.\u001b[39mones(visual_embeds\u001b[39m.\u001b[39mshape[:\u001b[39m-\u001b[39m\u001b[39m1\u001b[39m], dtype\u001b[39m=\u001b[39mtorch\u001b[39m.\u001b[39mfloat)\n",
      "\u001b[1;31mNameError\u001b[0m: name 'get_visual_embeddings' is not defined"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "from transformers import BertTokenizer, VisualBertModel\n",
    "\n",
    "model = VisualBertModel.from_pretrained(\"uclanlp/visualbert-vqa-coco-pre\")\n",
    "tokenizer = BertTokenizer.from_pretrained(\"bert-base-uncased\")\n",
    "\n",
    "inputs = tokenizer(\"What is the man eating?\", return_tensors=\"pt\")\n",
    "# this is a custom function that returns the visual embeddings given the image path\n",
    "visual_embeds = get_visual_embeddings(image_path)\n",
    "\n",
    "visual_token_type_ids = torch.ones(visual_embeds.shape[:-1], dtype=torch.long)\n",
    "visual_attention_mask = torch.ones(visual_embeds.shape[:-1], dtype=torch.float)\n",
    "inputs.update(\n",
    "    {\n",
    "        \"visual_embeds\": visual_embeds,\n",
    "        \"visual_token_type_ids\": visual_token_type_ids,\n",
    "        \"visual_attention_mask\": visual_attention_mask,\n",
    "    }\n",
    ")\n",
    "outputs = model(**inputs)\n",
    "last_hidden_state = outputs.last_hidden_state"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Downloading: 100%|██████████| 631/631 [00:00<00:00, 623kB/s]\n"
     ]
    }
   ],
   "source": [
    "from transformers import VisualBertConfig, VisualBertModel\n",
    "\n",
    "configuration = VisualBertConfig.from_pretrained(\"uclanlp/visualbert-nlvr2-coco-pre\")\n",
    "model = VisualBertModel(configuration)\n",
    "configuration = model.config\n",
    "\n",
    "model_type = \"visual_bert\"\n",
    "\n",
    "\n",
    "def __init__(\n",
    "        self,\n",
    "        vocab_size=30522,\n",
    "        hidden_size=768,\n",
    "        visual_embedding_dim=512,\n",
    "        num_hidden_layers=12,\n",
    "        num_attention_heads=12,\n",
    "        intermediate_size=3072,\n",
    "        hidden_act=\"gelu\",\n",
    "        hidden_dropout_prob=0.1,\n",
    "        attention_probs_dropout_prob=0.1,\n",
    "        max_position_embeddings=512,\n",
    "        type_vocab_size=2,\n",
    "        initializer_range=0.02,\n",
    "        layer_norm_eps=1e-12,\n",
    "        bypass_transformer=False,\n",
    "        special_visual_initialize=True,\n",
    "        pad_token_id=1,\n",
    "        bos_token_id=0,\n",
    "        eos_token_id=2,\n",
    "        **kwargs\n",
    "    ):\n",
    "        super().__init__(pad_token_id=pad_token_id, bos_token_id=bos_token_id, eos_token_id=eos_token_id, **kwargs)\n",
    "\n",
    "        self.vocab_size = vocab_size\n",
    "        self.max_position_embeddings = max_position_embeddings\n",
    "        self.hidden_size = hidden_size\n",
    "        self.visual_embedding_dim = visual_embedding_dim\n",
    "        self.num_hidden_layers = num_hidden_layers\n",
    "        self.num_attention_heads = num_attention_heads\n",
    "        self.intermediate_size = intermediate_size\n",
    "        self.hidden_act = hidden_act\n",
    "        self.hidden_dropout_prob = hidden_dropout_prob\n",
    "        self.attention_probs_dropout_prob = attention_probs_dropout_prob\n",
    "        self.initializer_range = initializer_range\n",
    "        self.type_vocab_size = type_vocab_size\n",
    "        self.layer_norm_eps = layer_norm_eps\n",
    "        self.bypass_transformer = bypass_transformer\n",
    "        self.special_visual_initialize = special_visual_initialize\n",
    "\n",
    "\n",
    "        \n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.0"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "ee4c60ed9f2d143d855c3de7cdf8e81ef9399a07140d5084c19be7d5d534dff2"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
