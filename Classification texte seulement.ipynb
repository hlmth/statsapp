{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "bd0ca625",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: nltk in /Users/juliette/Library/Python/3.9/lib/python/site-packages (3.8)\n",
      "Requirement already satisfied: regex>=2021.8.3 in /Users/juliette/Library/Python/3.9/lib/python/site-packages (from nltk) (2022.10.31)\n",
      "Requirement already satisfied: tqdm in /usr/local/lib/python3.9/site-packages (from nltk) (4.64.1)\n",
      "Requirement already satisfied: joblib in /usr/local/Cellar/jupyterlab/3.3.2/libexec/lib/python3.9/site-packages (from nltk) (1.2.0)\n",
      "Requirement already satisfied: click in /Users/juliette/Library/Python/3.9/lib/python/site-packages (from nltk) (8.1.3)\n",
      "\u001b[33mWARNING: Value for scheme.platlib does not match. Please report this to <https://github.com/pypa/pip/issues/10151>\n",
      "distutils: /Users/juliette/Library/Python/3.9/lib/python/site-packages\n",
      "sysconfig: /Users/juliette/Library/Python/3.9/lib/python3.9/site-packages\u001b[0m\n",
      "\u001b[33mWARNING: Value for scheme.purelib does not match. Please report this to <https://github.com/pypa/pip/issues/10151>\n",
      "distutils: /Users/juliette/Library/Python/3.9/lib/python/site-packages\n",
      "sysconfig: /Users/juliette/Library/Python/3.9/lib/python3.9/site-packages\u001b[0m\n",
      "\u001b[33mWARNING: Additional context:\n",
      "user = True\n",
      "home = None\n",
      "root = None\n",
      "prefix = None\u001b[0m\n",
      "\u001b[33mWARNING: You are using pip version 21.3.1; however, version 22.3.1 is available.\n",
      "You should consider upgrading via the '/usr/local/Cellar/jupyterlab/3.3.2/libexec/bin/python3.9 -m pip install --upgrade pip' command.\u001b[0m\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "pip install --user -U nltk"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "8440af39",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting gensim\n",
      "  Downloading gensim-4.2.0-cp39-cp39-macosx_10_9_x86_64.whl (24.0 MB)\n",
      "     |████████████████████████████████| 24.0 MB 3.7 MB/s            \n",
      "\u001b[?25hRequirement already satisfied: numpy>=1.17.0 in /usr/local/lib/python3.9/site-packages (from gensim) (1.23.4)\n",
      "Requirement already satisfied: scipy>=0.18.1 in /usr/local/Cellar/jupyterlab/3.3.2/libexec/lib/python3.9/site-packages (from gensim) (1.9.3)\n",
      "Collecting smart-open>=1.8.1\n",
      "  Downloading smart_open-6.3.0-py3-none-any.whl (56 kB)\n",
      "     |████████████████████████████████| 56 kB 3.1 MB/s            \n",
      "\u001b[?25hInstalling collected packages: smart-open, gensim\n",
      "Successfully installed gensim-4.2.0 smart-open-6.3.0\n",
      "\u001b[33mWARNING: You are using pip version 21.3.1; however, version 22.3.1 is available.\n",
      "You should consider upgrading via the '/usr/local/Cellar/jupyterlab/3.3.2/libexec/bin/python3.9 -m pip install --upgrade pip' command.\u001b[0m\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "pip install gensim"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "1abeff86",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "b00458a0",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package punkt to /Users/juliette/nltk_data...\n",
      "[nltk_data]   Package punkt is already up-to-date!\n",
      "[nltk_data] Downloading package averaged_perceptron_tagger to\n",
      "[nltk_data]     /Users/juliette/nltk_data...\n",
      "[nltk_data]   Package averaged_perceptron_tagger is already up-to-\n",
      "[nltk_data]       date!\n",
      "[nltk_data] Downloading package wordnet to\n",
      "[nltk_data]     /Users/juliette/nltk_data...\n",
      "[nltk_data]   Package wordnet is already up-to-date!\n"
     ]
    }
   ],
   "source": [
    "#for text pre-processing\n",
    "import re, string\n",
    "import nltk\n",
    "from nltk.tokenize import word_tokenize\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.tokenize import word_tokenize\n",
    "from nltk.stem import SnowballStemmer\n",
    "from nltk.corpus import wordnet\n",
    "from nltk.stem import WordNetLemmatizer\n",
    "nltk.download('punkt')\n",
    "nltk.download('averaged_perceptron_tagger')\n",
    "nltk.download('wordnet')\n",
    "#for model-building\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.naive_bayes import MultinomialNB\n",
    "from sklearn.metrics import classification_report, f1_score, accuracy_score, confusion_matrix\n",
    "from sklearn.metrics import roc_curve, auc, roc_auc_score\n",
    "# bag of words\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "#for word embedding\n",
    "import gensim\n",
    "from gensim.models import Word2Vec"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "68654e70",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_train = pd.read_json(\"train.jsonl\",lines=True)\n",
    "df_test = pd.read_json(\"test.jsonl\",lines=True)\n",
    "df_dev = pd.read_json(\"dev.jsonl\",lines=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "b574f5c4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>img</th>\n",
       "      <th>label</th>\n",
       "      <th>text</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>42953</td>\n",
       "      <td>img/42953.png</td>\n",
       "      <td>0</td>\n",
       "      <td>its their character not their color that matters</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>23058</td>\n",
       "      <td>img/23058.png</td>\n",
       "      <td>0</td>\n",
       "      <td>don't be afraid to love again everyone is not ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>13894</td>\n",
       "      <td>img/13894.png</td>\n",
       "      <td>0</td>\n",
       "      <td>putting bows on your pet</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>37408</td>\n",
       "      <td>img/37408.png</td>\n",
       "      <td>0</td>\n",
       "      <td>i love everything and everybody! except for sq...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>82403</td>\n",
       "      <td>img/82403.png</td>\n",
       "      <td>0</td>\n",
       "      <td>everybody loves chocolate chip cookies, even h...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      id            img  label  \\\n",
       "0  42953  img/42953.png      0   \n",
       "1  23058  img/23058.png      0   \n",
       "2  13894  img/13894.png      0   \n",
       "3  37408  img/37408.png      0   \n",
       "4  82403  img/82403.png      0   \n",
       "\n",
       "                                                text  \n",
       "0   its their character not their color that matters  \n",
       "1  don't be afraid to love again everyone is not ...  \n",
       "2                           putting bows on your pet  \n",
       "3  i love everything and everybody! except for sq...  \n",
       "4  everybody loves chocolate chip cookies, even h...  "
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_train.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e8975618",
   "metadata": {},
   "source": [
    "# EDA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "6119c474",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0    5450\n",
      "1    3050\n",
      "Name: label, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "#Distribution : \n",
    "x=df_train['label'].value_counts()\n",
    "print(x)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4ff8b255",
   "metadata": {},
   "source": [
    "Il y a 5450 memes non haineux et 3050 memes haineux"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "bff414f6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "id       0\n",
       "img      0\n",
       "label    0\n",
       "text     0\n",
       "dtype: int64"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Vérification des NA\n",
    "df_train.isna().sum()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e6cede12",
   "metadata": {},
   "source": [
    "Il n'y a aucune valeur manquante"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "cfd78326",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "12.79344262295082\n",
      "11.154495412844037\n"
     ]
    }
   ],
   "source": [
    "# Nombre de mots \n",
    "df_train_2 = df_train.copy()\n",
    "df_train_2['word_count'] = df_train_2['text'].apply(lambda x: len(str(x).split()))\n",
    "print(df_train_2[df_train_2['label']==1]['word_count'].mean()) # memes haineux\n",
    "print(df_train_2[df_train_2['label']==0]['word_count'].mean()) # memes non haineux"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "53cebef1",
   "metadata": {},
   "source": [
    "Il y a environ le même nombre de mots entre les deux types de même (en moyenne un de plus pour les mêmes haineux)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "f282326b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "68.48360655737704\n",
      "58.489724770642205\n"
     ]
    }
   ],
   "source": [
    "# Nombre de lettres\n",
    "df_train_2['char_count'] = df_train_2['text'].apply(lambda x: len(str(x)))\n",
    "print(df_train_2[df_train_2['label']==1]['char_count'].mean()) #memes haineux\n",
    "print(df_train_2[df_train_2['label']==0]['char_count'].mean()) #memes non haineux"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d51d5c1d",
   "metadata": {},
   "source": [
    "Il y a environ une dizaine de caractères en plus dans les mêmes haineux"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "22db169a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>img</th>\n",
       "      <th>label</th>\n",
       "      <th>text</th>\n",
       "      <th>word_count</th>\n",
       "      <th>char_count</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>42953</td>\n",
       "      <td>img/42953.png</td>\n",
       "      <td>0</td>\n",
       "      <td>its their character not their color that matters</td>\n",
       "      <td>8</td>\n",
       "      <td>48</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>23058</td>\n",
       "      <td>img/23058.png</td>\n",
       "      <td>0</td>\n",
       "      <td>don't be afraid to love again everyone is not ...</td>\n",
       "      <td>12</td>\n",
       "      <td>58</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>13894</td>\n",
       "      <td>img/13894.png</td>\n",
       "      <td>0</td>\n",
       "      <td>putting bows on your pet</td>\n",
       "      <td>5</td>\n",
       "      <td>24</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>37408</td>\n",
       "      <td>img/37408.png</td>\n",
       "      <td>0</td>\n",
       "      <td>i love everything and everybody! except for sq...</td>\n",
       "      <td>11</td>\n",
       "      <td>70</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>82403</td>\n",
       "      <td>img/82403.png</td>\n",
       "      <td>0</td>\n",
       "      <td>everybody loves chocolate chip cookies, even h...</td>\n",
       "      <td>7</td>\n",
       "      <td>51</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      id            img  label  \\\n",
       "0  42953  img/42953.png      0   \n",
       "1  23058  img/23058.png      0   \n",
       "2  13894  img/13894.png      0   \n",
       "3  37408  img/37408.png      0   \n",
       "4  82403  img/82403.png      0   \n",
       "\n",
       "                                                text  word_count  char_count  \n",
       "0   its their character not their color that matters           8          48  \n",
       "1  don't be afraid to love again everyone is not ...          12          58  \n",
       "2                           putting bows on your pet           5          24  \n",
       "3  i love everything and everybody! except for sq...          11          70  \n",
       "4  everybody loves chocolate chip cookies, even h...           7          51  "
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_train_2.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b47141a7",
   "metadata": {},
   "source": [
    "# Preparation de la base avant la classification"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "65bb9c39",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package stopwords to\n",
      "[nltk_data]     /Users/juliette/nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "nltk.download('stopwords')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "9a43653c",
   "metadata": {},
   "outputs": [],
   "source": [
    "#On enlève la ponctuatoin et les strips\n",
    "def preprocess(text):\n",
    "    text = text.lower() \n",
    "    text=text.strip()  #suppression des caractères de tête et de queue\n",
    "    text=re.compile('<.*?>').sub('', text) \n",
    "    text = re.compile('[%s]' % re.escape(string.punctuation)).sub(' ', text)  \n",
    "    text = re.sub('\\s+', ' ', text)  \n",
    "    text = re.sub(r'\\[[0-9]*\\]',' ',text) \n",
    "    text=re.sub(r'[^\\w\\s]', '', str(text).lower().strip())\n",
    "    text = re.sub(r'\\d',' ',text) \n",
    "    text = re.sub(r'\\s+',' ',text) \n",
    "    return text\n",
    "\n",
    " \n",
    "# STOPWORD REMOVAL : on enlève les mots inutiles \"the\" etc.\n",
    "def stopword(string):\n",
    "    a= [i for i in string.split() if i not in stopwords.words('english')]\n",
    "    return ' '.join(a)\n",
    "\n",
    "#LEMMATIZATION \n",
    "# On initialise le lemmatizer\n",
    "wl = WordNetLemmatizer()\n",
    " \n",
    "# This is a helper function to map NTLK position tags\n",
    "\n",
    "#WordNetLemmatizer a besoin des balises Pos pour comprendre si le mot est un nom, \n",
    "#un verbe, un adjectif, etc. Par défaut, elle est définie sur Noun\n",
    "\n",
    "def get_wordnet_pos(tag):\n",
    "    if tag.startswith('J'):\n",
    "        return wordnet.ADJ\n",
    "    elif tag.startswith('V'):\n",
    "        return wordnet.VERB\n",
    "    elif tag.startswith('N'):\n",
    "        return wordnet.NOUN\n",
    "    elif tag.startswith('R'):\n",
    "        return wordnet.ADV\n",
    "    else:\n",
    "        return wordnet.NOUN\n",
    "\n",
    "# Tokenize \n",
    "def lemmatizer(string):\n",
    "    word_pos_tags = nltk.pos_tag(word_tokenize(string)) # Get position tags\n",
    "    a=[wl.lemmatize(tag[0], get_wordnet_pos(tag[1])) for idx, tag in enumerate(word_pos_tags)] # Map the position tag and lemmatize the word/token\n",
    "    return \" \".join(a)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "a2b5ea9a",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package omw-1.4 to\n",
      "[nltk_data]     /Users/juliette/nltk_data...\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import nltk\n",
    "nltk.download('omw-1.4')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "c1eba4da",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>img</th>\n",
       "      <th>label</th>\n",
       "      <th>text</th>\n",
       "      <th>clean_text</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>42953</td>\n",
       "      <td>img/42953.png</td>\n",
       "      <td>0</td>\n",
       "      <td>its their character not their color that matters</td>\n",
       "      <td>character color matter</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>23058</td>\n",
       "      <td>img/23058.png</td>\n",
       "      <td>0</td>\n",
       "      <td>don't be afraid to love again everyone is not ...</td>\n",
       "      <td>afraid love everyone like ex</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>13894</td>\n",
       "      <td>img/13894.png</td>\n",
       "      <td>0</td>\n",
       "      <td>putting bows on your pet</td>\n",
       "      <td>put bow pet</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>37408</td>\n",
       "      <td>img/37408.png</td>\n",
       "      <td>0</td>\n",
       "      <td>i love everything and everybody! except for sq...</td>\n",
       "      <td>love everything everybody except squirrel hate...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>82403</td>\n",
       "      <td>img/82403.png</td>\n",
       "      <td>0</td>\n",
       "      <td>everybody loves chocolate chip cookies, even h...</td>\n",
       "      <td>everybody love chocolate chip cooky even hitler</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      id            img  label  \\\n",
       "0  42953  img/42953.png      0   \n",
       "1  23058  img/23058.png      0   \n",
       "2  13894  img/13894.png      0   \n",
       "3  37408  img/37408.png      0   \n",
       "4  82403  img/82403.png      0   \n",
       "\n",
       "                                                text  \\\n",
       "0   its their character not their color that matters   \n",
       "1  don't be afraid to love again everyone is not ...   \n",
       "2                           putting bows on your pet   \n",
       "3  i love everything and everybody! except for sq...   \n",
       "4  everybody loves chocolate chip cookies, even h...   \n",
       "\n",
       "                                          clean_text  \n",
       "0                             character color matter  \n",
       "1                       afraid love everyone like ex  \n",
       "2                                        put bow pet  \n",
       "3  love everything everybody except squirrel hate...  \n",
       "4    everybody love chocolate chip cooky even hitler  "
      ]
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def finalpreprocess(string):\n",
    "    return lemmatizer(stopword(preprocess(string)))\n",
    "df_train['clean_text'] = df_train['text'].apply(lambda x: finalpreprocess(x))\n",
    "df_dev['clean_text'] = df_dev['text'].apply(lambda x: finalpreprocess(x))\n",
    "df_train.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "b9092a94",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>img</th>\n",
       "      <th>label</th>\n",
       "      <th>text</th>\n",
       "      <th>clean_text</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>8291</td>\n",
       "      <td>img/08291.png</td>\n",
       "      <td>1</td>\n",
       "      <td>white people is this a shooting range</td>\n",
       "      <td>white people shoot range</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>46971</td>\n",
       "      <td>img/46971.png</td>\n",
       "      <td>1</td>\n",
       "      <td>bravery at its finest</td>\n",
       "      <td>bravery fine</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3745</td>\n",
       "      <td>img/03745.png</td>\n",
       "      <td>1</td>\n",
       "      <td>your order comes to $37.50 and your white priv...</td>\n",
       "      <td>order come white privilege discount brings total</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>83745</td>\n",
       "      <td>img/83745.png</td>\n",
       "      <td>1</td>\n",
       "      <td>it is time.. to send these parasites back to t...</td>\n",
       "      <td>time send parasite back desert</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>80243</td>\n",
       "      <td>img/80243.png</td>\n",
       "      <td>1</td>\n",
       "      <td>mississippi wind chime</td>\n",
       "      <td>mississippi wind chime</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      id            img  label  \\\n",
       "0   8291  img/08291.png      1   \n",
       "1  46971  img/46971.png      1   \n",
       "2   3745  img/03745.png      1   \n",
       "3  83745  img/83745.png      1   \n",
       "4  80243  img/80243.png      1   \n",
       "\n",
       "                                                text  \\\n",
       "0              white people is this a shooting range   \n",
       "1                              bravery at its finest   \n",
       "2  your order comes to $37.50 and your white priv...   \n",
       "3  it is time.. to send these parasites back to t...   \n",
       "4                             mississippi wind chime   \n",
       "\n",
       "                                         clean_text  \n",
       "0                          white people shoot range  \n",
       "1                                      bravery fine  \n",
       "2  order come white privilege discount brings total  \n",
       "3                    time send parasite back desert  \n",
       "4                            mississippi wind chime  "
      ]
     },
     "execution_count": 48,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_dev.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "id": "fccf67ec",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Mise en vecteur (word embedding)\n",
    "\n",
    "#Création du train et du test (on test sur le dev car on a pas les labels sur le test)\n",
    "\n",
    "X_train, y_train = (df_train[\"clean_text\"],df_train[\"label\"])\n",
    "X_test, y_test = (df_dev[\"clean_text\"],df_dev[\"label\"])\n",
    "\n",
    "#X contient les mots et y contient les labels correspondants\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "id": "b097294a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0                               character color matter\n",
       "1                         afraid love everyone like ex\n",
       "2                                          put bow pet\n",
       "3    love everything everybody except squirrel hate...\n",
       "4      everybody love chocolate chip cooky even hitler\n",
       "Name: clean_text, dtype: object"
      ]
     },
     "execution_count": 61,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "id": "014d8120",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0    0\n",
       "1    0\n",
       "2    0\n",
       "3    0\n",
       "4    0\n",
       "Name: label, dtype: int64"
      ]
     },
     "execution_count": 63,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_train.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "id": "6e2bee0b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0                            white people shoot range\n",
       "1                                        bravery fine\n",
       "2    order come white privilege discount brings total\n",
       "3                      time send parasite back desert\n",
       "4                              mississippi wind chime\n",
       "Name: clean_text, dtype: object"
      ]
     },
     "execution_count": 64,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_test.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "id": "51ae3ae2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0    1\n",
       "1    1\n",
       "2    1\n",
       "3    1\n",
       "4    1\n",
       "Name: label, dtype: int64"
      ]
     },
     "execution_count": 65,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_test.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "id": "c8baaece",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Tf-Idf (méthode pour mathématiser le texte)\n",
    "tfidf_vectorizer = TfidfVectorizer(use_idf=True)\n",
    "X_train_vectors_tfidf = tfidf_vectorizer.fit_transform(X_train) # on obtient des matrices\n",
    "X_test_vectors_tfidf = tfidf_vectorizer.transform(X_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1613982b",
   "metadata": {},
   "source": [
    "# Classification"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "517469a9",
   "metadata": {},
   "source": [
    "## Régression linéaire"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "id": "e290fc5f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.51      0.81      0.63       250\n",
      "           1       0.55      0.23      0.32       250\n",
      "\n",
      "    accuracy                           0.52       500\n",
      "   macro avg       0.53      0.52      0.48       500\n",
      "weighted avg       0.53      0.52      0.48       500\n",
      "\n",
      "Confusion Matrix: [[203  47]\n",
      " [193  57]]\n",
      "AUC: 0.566544\n"
     ]
    }
   ],
   "source": [
    "#FITTING THE CLASSIFICATION MODEL using Logistic Regression(tf-idf)\n",
    "lr_tfidf=LogisticRegression(solver = 'liblinear', C=10, penalty = 'l2')\n",
    "lr_tfidf.fit(X_train_vectors_tfidf, y_train)  \n",
    "\n",
    "#Predict y value for test dataset\n",
    "y_predict = lr_tfidf.predict(X_test_vectors_tfidf)\n",
    "y_prob = lr_tfidf.predict_proba(X_test_vectors_tfidf)[:,1]\n",
    "print(classification_report(y_test,y_predict))\n",
    "print('Confusion Matrix:',confusion_matrix(y_test, y_predict))\n",
    " \n",
    "fpr, tpr, thresholds = roc_curve(y_test, y_prob)\n",
    "roc_auc = auc(fpr, tpr)\n",
    "print('AUC:', roc_auc)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5445aa38",
   "metadata": {},
   "source": [
    "*Interprétation* : \n",
    "\n",
    "   *La précision* : \n",
    "   \n",
    "Sur l'ensemble des memes que le modèle à prédit comme non haineux (label 1) seuls 55% le sont réellement.\n",
    "Sur l'ensemble des memes que le modèle à prédit comme haineux (label 0), 51% le sont réellement.\n",
    "\n",
    "      "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8f856fa3",
   "metadata": {},
   "source": [
    "*L'accuracy* : \n",
    "\n",
    "La proportion de mèmes correctement prédis est de 0.52. Ce n'est pas un bon résultat. \n",
    "\n",
    "CCl : Mauvaise prédiction pour les memes non haineux. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3a1ad1f9",
   "metadata": {},
   "source": [
    "## Naive Bayes Classifier Algorithm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "id": "99a8ddf8",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn import model_selection, naive_bayes, svm\n",
    "from sklearn.metrics import accuracy_score\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "id": "5dbb6f6f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.51      0.94      0.66       250\n",
      "           1       0.59      0.08      0.14       250\n",
      "\n",
      "    accuracy                           0.51       500\n",
      "   macro avg       0.55      0.51      0.40       500\n",
      "weighted avg       0.55      0.51      0.40       500\n",
      "\n",
      "Naive Bayes Accuracy Score ->  0.512\n"
     ]
    }
   ],
   "source": [
    "# fit the training dataset on the NB classifier\n",
    "\n",
    "Naive = naive_bayes.MultinomialNB()\n",
    "Naive.fit(X_train_vectors_tfidf,y_train)\n",
    "\n",
    "# predict the labels on validation dataset\n",
    "\n",
    "predictions_NB = Naive.predict(X_test_vectors_tfidf)\n",
    "\n",
    "\n",
    "#classification report\n",
    "print(classification_report(y_test,predictions_NB))\n",
    "\n",
    "# Accuracy\n",
    "print(\"Naive Bayes Accuracy Score -> \",accuracy_score(predictions_NB, y_test))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b352daeb",
   "metadata": {},
   "source": [
    "On retrouve une accuracy de 0.51. Ce n'est pas un bon résulat. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9d29577d",
   "metadata": {},
   "source": [
    "## SVM — Support Vector Machine"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "id": "457d92bf",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.52      0.89      0.66       250\n",
      "           1       0.63      0.19      0.29       250\n",
      "\n",
      "    accuracy                           0.54       500\n",
      "   macro avg       0.58      0.54      0.48       500\n",
      "weighted avg       0.58      0.54      0.48       500\n",
      "\n",
      "SVM Accuracy Score ->  0.54\n"
     ]
    }
   ],
   "source": [
    "# fit the training dataset on the classifier\n",
    "\n",
    "SVM = svm.SVC(C=1.0, kernel='linear', degree=3, gamma='auto')\n",
    "SVM.fit(X_train_vectors_tfidf,y_train)\n",
    "\n",
    "# predict the labels on validation dataset\n",
    "\n",
    "predictions_SVM = SVM.predict(X_test_vectors_tfidf)\n",
    "\n",
    "#classification report\n",
    "print(classification_report(y_test,predictions_SVM))\n",
    "\n",
    "# Use accuracy_score function to get the accuracy\n",
    "\n",
    "print(\"SVM Accuracy Score -> \",accuracy_score(predictions_SVM, y_test))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0ec9cb03",
   "metadata": {},
   "source": [
    "On obtient une meilleure accuracy qu'avec les modèles précédents: 0.54. Cependant, ce résultat n'est toujours pas satisfaisant. \n",
    "\n",
    "On en déduit que l'analyse textuelle seule n'est pas suffisante pour catégoriser les mèmes en haineux ou non haineux. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f739a0ba",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
