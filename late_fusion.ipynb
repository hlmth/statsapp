{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from __future__ import print_function\n",
    "from __future__ import division\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "import numpy as np\n",
    "import torchvision\n",
    "from torchvision import datasets, models, transforms\n",
    "import matplotlib.pyplot as plt\n",
    "import time\n",
    "import os\n",
    "import copy\n",
    "import pandas as pd\n",
    "from transformers import BertModel\n",
    "print(\"PyTorch Version: \",torch.__version__)\n",
    "print(\"Torchvision Version: \",torchvision.__version__)\n",
    "\n",
    "device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
    "\n",
    "print(device)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "num_epochs = 1\n",
    "\n",
    "batch_size = 8\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from PIL import Image\n",
    "\n",
    "class MyDataset(torch.utils.data.Dataset):\n",
    "  'Caractérise un jeu de données pour PyTorch'\n",
    "  def __init__(self, transforms = None, root_dir = 'data', mode = 'train'):\n",
    "        'Initialisation'\n",
    "        self.df = pd.read_json(f\"{root_dir}/{mode}.jsonl\", lines=True)\n",
    "        self.labels = self.df.label\n",
    "        self.image_names = self.df.img\n",
    "        self.transforms = transforms\n",
    "        self.root_dir = root_dir\n",
    "#        print(len(self.labels[self.labels == 0])/len(self.labels))\n",
    "      \n",
    "  def __len__(self):\n",
    "        \"Représente le nombre total d'exemples du jeu de données\"\n",
    "        return len(self.labels)\n",
    "\n",
    "  def __getitem__(self, idx):\n",
    "      'Génère un exemple à partir du jeu de données'\n",
    "      # Sélection de l'exemple\n",
    "      if torch.is_tensor(idx):\n",
    "            idx = idx.tolist()\n",
    "\n",
    "      image_path = f\"{self.root_dir}/{self.image_names.iloc[idx]}\"\n",
    "\n",
    "      img = Image.open(image_path, ).convert('RGB')\n",
    "\n",
    "      if self.transforms :\n",
    "            img = self.transforms(img)\n",
    "\n",
    "      return img, self.labels.iloc[idx]\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Data augmentation and normalization for training\n",
    "# Just normalization for validation\n",
    "alpha_buster = lambda x: x[:3, :, :]\n",
    "input_size = 224\n",
    "data_transforms = {\n",
    "    'train': transforms.Compose([\n",
    "        transforms.RandomResizedCrop(input_size),\n",
    "        transforms.RandomHorizontalFlip(),\n",
    "        transforms.ToTensor(),\n",
    "        transforms.Normalize([0.485, 0.456, 0.406], [0.229, 0.224, 0.225]),\n",
    "        alpha_buster\n",
    "    ]),\n",
    "    'val': transforms.Compose([\n",
    "        transforms.Resize(input_size),\n",
    "        transforms.CenterCrop(input_size),\n",
    "        transforms.ToTensor(),\n",
    "        transforms.Normalize([0.485, 0.456, 0.406], [0.229, 0.224, 0.225]),\n",
    "        alpha_buster\n",
    "    ]),\n",
    "}\n",
    "\n",
    "print(\"Initializing Datasets and Dataloaders...\")\n",
    "\n",
    "# Create training and validation datasets\n",
    "image_datasets = {x: MyDataset(transforms = data_transforms[x], mode = x) for x in ['train', 'val']}\n",
    "\n",
    "# Create training and validation dataloaders\n",
    "dataloaders_dict = {x: torch.utils.data.DataLoader(image_datasets[x], batch_size=batch_size, shuffle=True, num_workers=4) for x in ['train', 'val']}\n",
    "\n",
    "# Detect if we have a GPU available\n",
    "device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# définir le modèle Bert\n",
    "bert_model = BertModel.from_pretrained('bert-base-uncased')\n",
    "\n",
    "# définir le modèle ResNet18\n",
    "resnet18_model = torch.hub.load('pytorch/vision:v0.9.0', 'resnet18', pretrained=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# définir une classe de modèle qui effectue la moyenne des sorties des deux modèles\n",
    "class FusionModel(torch.nn.Module):\n",
    "    def __init__(self, bert_model, resnet18_model):\n",
    "        super(FusionModel, self).__init__()\n",
    "        self.bert_model = bert_model\n",
    "        self.resnet18_model = resnet18_model\n",
    "        self.fc = torch.nn.Linear(768+512, 1) # 768 est la dimension de sortie de Bert, 512 est la dimension de sortie de ResNet18, 1 est le nombre de classes pour la classification binaire\n",
    "        \n",
    "    def forward(self, input_ids, attention_mask, image):\n",
    "        bert_output = self.bert_model(input_ids=input_ids, attention_mask=attention_mask)[1]\n",
    "        resnet_output = self.resnet18_model(image)\n",
    "        fusion_output = torch.cat((bert_output, resnet_output), dim=1)\n",
    "        output = self.fc(fusion_output)\n",
    "        output = torch.sigmoid(output)\n",
    "        return output\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "# initialiser une instance de FusionModel\n",
    "fusion_model = FusionModel(bert_model, resnet18_model)\n",
    "print(fusion_model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_late_fusion(model, dataloaders, resnet, bert, criterion, optimizer, num_epochs):\n",
    "    since = time.time()\n",
    "    val_acc_history = []\n",
    "\n",
    "    best_model_wts = copy.deepcopy(model.state_dict())\n",
    "    best_acc = 0.0\n",
    "\n",
    "    for epoch in range(num_epochs):\n",
    "        print('Epoch {}/{}'.format(epoch, num_epochs - 1))\n",
    "        print('-' * 10)\n",
    "        for phase in ['train', 'test']:\n",
    "\n",
    "            for inputs, input_ids, attention_masks, labels in dataloaders:\n",
    "                # passer les images à travers ResNet18\n",
    "                inputs = inputs.to(device)\n",
    "                resnet_output = resnet18_model(inputs)\n",
    "                \n",
    "                # passer les textes à travers Bert\n",
    "                input_ids = input_ids.to(device)\n",
    "                attention_masks = attention_masks.to(device)\n",
    "                bert_output = bert_model(input_ids=input_ids, attention_mask=attention_masks)[1]\n",
    "                \n",
    "                optimizer.zero_grad()\n",
    "\n",
    "                with torch.set_grad_enabled(phase == 'train'):\n",
    "                    # effectuer la fusion\n",
    "                    fusion_output = torch.cat((bert_output, resnet_output), dim=1)\n",
    "                    # effectuer la prédiction et calculer la perte\n",
    "                    outputs = fusion_model(input_ids, attention_masks, inputs)\n",
    "                    loss = criterion(outputs, labels.float().unsqueeze(1).to(device))\n",
    "                \n",
    "                    if phase == 'train':\n",
    "                        # rétropropager et mettre à jour les poids\n",
    "                        loss.backward()\n",
    "                        optimizer.step()\n",
    "                    preds = (outputs > 0.5).float()\n",
    "                # statistics\n",
    "                running_loss += loss.item() * inputs.size(0)\n",
    "                running_corrects += torch.sum(preds == labels.data)\n",
    "\n",
    "            epoch_loss = running_loss / len(dataloaders[phase].dataset)\n",
    "            epoch_acc = running_corrects.double() / len(dataloaders[phase].dataset)\n",
    "\n",
    "            print('{} Loss: {:.4f} Acc: {:.4f}'.format(phase, epoch_loss, epoch_acc))\n",
    "            \n",
    "                # deep copy the model\n",
    "            if phase == 'val' and epoch_acc > best_acc:\n",
    "                best_acc = epoch_acc\n",
    "                best_model_wts = copy.deepcopy(model.state_dict())\n",
    "            if phase == 'val':\n",
    "                val_acc_history.append(epoch_acc)\n",
    "\n",
    "    time_elapsed = time.time() - since\n",
    "    print('Training complete in {:.0f}m {:.0f}s'.format(time_elapsed // 60, time_elapsed % 60))\n",
    "    print('Best val Acc: {:4f}'.format(best_acc))\n",
    "\n",
    "    # load best model weights\n",
    "    model.load_state_dict(best_model_wts)\n",
    "\n",
    "    return fusion_model, "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# définir la fonction de perte et l'optimiseur\n",
    "criterion = torch.nn.BCELoss()\n",
    "optimizer = torch.optim.Adam(fusion_model.parameters(), lr=0.001)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fusion_model, hist = train_late_fusion(fusion_model, dataloaders_dict, resnet18_model, bert_model , criterion, optimizer, num_epochs)"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
